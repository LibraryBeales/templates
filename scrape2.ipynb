{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by R. David Beales for the [Kelvin Smith Library](https://case.edu/library/) at [Case Western Reserve University](https://case.edu) under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email rdb104@case.edu.<br />\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping: Exploring Website Structure and Getting Specific Data from Web Scraping\n",
    "\n",
    "**Description:** This lesson introduces basic website structure and how to identify elements for use in web scraping.  \n",
    "\n",
    "**Use Case:** For Learners (Additional explanation, not ideal for researchers)\n",
    "\n",
    "**Difficulty:** Beginner\n",
    "\n",
    "**Completion time:** 60 minutes\n",
    "\n",
    "**Knowledge Required:** Basic Python\n",
    "\n",
    "**Knowledge Recommended:** HTML Structure\n",
    "\n",
    "**Data Format:** `html`, `txt`, `py`, `csv`\n",
    "\n",
    "**Libraries Used:** `requests` `BeautifulSoup` \n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As in the previous tutorial, we will be using [Books to Scrape](https://books.toscrape.com/) as our test website for this tutorial.  The site exists just to provide a platform for people to practice web scraping.  You may want to keep the website open in a another browser tab so you can compare the data we are getting with the website as a regular user will see it. \n",
    "\n",
    "In this project you will:\n",
    "1. Use the `Inspect` tool in your web browser to explore the structure of the <a href=\"https://books.toscrape.com/\">Books to Scrape</a> website.\n",
    "2. Understand how book titles on the site are tagged/classified. \n",
    "3. Understand and use a python script to crawl the web page and extract only the data that meets the classification criteria we identified for titles in step 2.\n",
    "4. Look at the list of titles we scraped.  Identify problems with the data and explore an alternative strategy of using Beautiful Soup to get the correct titles.\n",
    "5. Write the list of correct titles to a file. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Inspect` Tool and how to use it.\n",
    "\n",
    "Modern web broswers provide powerful tools for exploring the structure of web pages.  In Firefox, (<a url='https://duckduckgo.com/?t=ffab&q=why+use+firefox'>You should be using Firefox.</a>) right clicking anywhere on a web page will open the context menu.  One of the options in the context menu is `Inspect`.  You can also find the `Inspect` option in Chrome if you are still using that for some reason...\n",
    "\n",
    "In your browser, right click on a book title on [Books to Scrape](https://books.toscrape.com) and then click on the `Inspect` option in the context menu.  You will see the Web Developer Tools open up and see the html structure in the Inspector panel.  \n",
    "\n",
    " ![title](img/inspect1.png)  ![title](img/inspect2.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that as you move the mouse around the inspector panel, it will highlight the piece of the web page that the code you are hovering over is being used to create.  It should be obvious now how powerful this tool is for exploring the structure of pages.  \n",
    "\n",
    "Now let's take a minute to talk about the HTML we are looking at in the Inspector panel.  \n",
    "\n",
    "HTML elements make up the page.  Each element has tags and attrubutes for its syntax that define how the content is displayed.\n",
    "\n",
    "If we're looking at the title of the books, as shown in the images above, we see html like this.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3>\n",
    "    <a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `<h3>` tag and the `<a>` tag are elements.  The `<h3>` tag has no syntax, but the `<a>` tag has an `<href>` atribute and a `<title>` attribute. The affected content is the text \"A Light in the...\".  So when you see that text on the page, it is displayed as a heading 3 as indicated by the `<h3>` tag and it is also displayed as a link to another page because of the `a` tag and the `html` attribute.  This image shows the structure of the `<a>` tag.\n",
    "\n",
    "\n",
    "![title](img/htmlelements.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So!  Looking at the image above, we can tell that if we want to collect a list of book titles, we will have to use the `title` attribute of the `<a>` tag to get that information.  We know from the last lesson that we can scrape the entire HTML document, but how do we tell the web scraper to only look for the `title` attribute of the `<a>` tag?\n",
    "\n",
    "We will use python package called Beautiful Soup to manage a process called parsing. \n",
    "\n",
    "Now, let's get back to scraping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Fetch the page\n",
    "results = requests.get(\"https://books.toscrape.com/\")\n",
    "\n",
    "# 2.Get the page content and assign it to the varaible 'content'\n",
    "content = results.text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we always do when beginning a scraping project, but now we are going to start using BeautifulSoup to sift through that content for the pieces we are interested in. Beautiful Soup we use the “soup” object to find elements in a website. To create this object execute the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Create the soup\n",
    "soup = BeautifulSoup(content, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created the `soup` so now we can look through it to find the data we are looking for.\n",
    "\n",
    "There are two main ways to parse the results using Beautiful Soup, `find()` and `findall()`.  `find()` gets the first element that matches a specific tag name, class name, and/or id.  `findall()` will get all the elements that match those criteria and put them in a python list.\n",
    "\n",
    "The syntax is `variable = soup.find('tag', AttributeName='Value)`\n",
    "\n",
    "We can omit any of the arguments of the `find` function if we don't need to specify an attribute value. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at some examples of how to locate elements with Beautiful Soup. We’ll be using this HTML for the first book from [Books to Scrape](https://books.toscrape.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h3><a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also scrape the title information using the `h3` tags.  If you look at this line of HTML, you can see that the title, as well as a link to product page for the specific book, are in bewteen the `h3` tags.\n",
    "\n",
    "`<h3><a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>`\n",
    "\n",
    "We can get just the text from what we've scraped using the `text` property.\n",
    "\n",
    "Let's use the syntax in the examples below `variable = soup.find('tag', AttributeName='Value)`. In this case we will omit the `AttributeValue` argument.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the title element using the h3 tag.\n",
    "title_element = soup.find('h3')\n",
    "\n",
    "# Get the text from the title element.\n",
    "title_text = title_element.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the `title_text` variable using the code block below.  Let's see if we stored the book title there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting!\n",
    "As you can see, we've got the title text, but it is not the full title of the book.  The full title is \"A Light in the Attic\" but we only scraped the abbreviated title for display on the web page.  We would probably want to scrape the complete title of the book in order to create a meaningful list.  What if later on we were looking for books aobut attics in our data?!\n",
    "\n",
    "Luckily there is a solution.  \n",
    "\n",
    "`<h3><a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>`\n",
    "\n",
    "If we look at the `h3` tags again, we can see there is also a `title` attribute of the `<a>` tags that contains the complete title of the book.  Just like we used the `find()` function on the `soup` we created, we can use `find()` on parts of the soup as well.\n",
    "\n",
    "First we find the `h3` element. Second, we look in that element for the `a` element.  Finally, we use the `get` function to retrieve the `title` attribute.  Remember that there are nested tags in the html, so we are drilling own one level at a time to find what we need.\n",
    "\n",
    "And we can use a short `if/esle` statement to automatically check what we scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_element = soup.find('h3')\n",
    "\n",
    "# Find the <a> element within the <h3> element\n",
    "a_element = h3_element.find('a')\n",
    "\n",
    "# Extract the title attribute of the <a> element\n",
    "if a_element:\n",
    "    title_attribute = a_element.get('title')\n",
    "    print(\"Title Attribute:\", title_attribute)\n",
    "else:\n",
    "    print(\"No <a> element found within <h3>.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AHA!  We have a complete title!  But that's only one...  \n",
    "\n",
    "In order to find all the titles we need to modify our code so we are using the `find_all()` instead of `find()`.\n",
    "\n",
    "Additionally, we are now looking through multiple `h3` elements instead of one, so we are going to have to use a `for` loop.\n",
    "\n",
    "\n",
    "Let's break down the loop:\n",
    "\n",
    "`h3_elements = soup.find_all('h3')`: This line finds all the `<h3>` elements in the parsed HTML content using BeautifulSoup's find_all method and stores them in the h3_elements variable. This creates a collection (list-like object) containing all the `<h3>` elements found.\n",
    "\n",
    "`for h3_element in h3_elements:`: The for loop starts here. It iterates over each `<h3>` element found in the h3_elements collection. For each iteration, the current `<h3>` element is stored in the variable h3_element.\n",
    "\n",
    "`a_element = h3_element.find('a')`: Within each iteration of the loop, `h3_element.find('a')` looks for the first `<a>` element inside the current `<h3>` element (h3_element). If an `<a>` element is found, it is stored in the variable a_element. If no `<a>` element exists within the current `<h3>` element, a_element will be None.\n",
    "\n",
    "`if a_element:`: This if statement checks if an `<a>` element was found within the current `<h3>` element. If a_element is not None, indicating that an `<a>` element exists, it proceeds to the next step.\n",
    "\n",
    "`title_attribute = a_element.get('title')`: This line extracts the value of the title attribute from the found `<a>` element (a_element) using the get() method and stores it in the variable title_attribute.\n",
    "\n",
    "`title_attributes.append(title_attribute)`: If a title_attribute was obtained (meaning the `<a>` element had a title attribute), it appends this title_attribute value to the title_attributes list.\n",
    "\n",
    "The loop continues this process for each `<h3>` element found in the HTML content, collecting the title attributes of the nested `<a>` elements and storing them in the title_attributes list.\n",
    "\n",
    "Finally, `print(\"Title Attributes List:\", title_attributes)` displays the list for us so we can check that the data we've scraped is indeed what we were looking for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all <h3> elements\n",
    "h3_elements = soup.find_all('h3')\n",
    "\n",
    "# Initialize an empty list to store title attributes\n",
    "title_attributes = []\n",
    "\n",
    "# Iterate through each <h3> element to find and extract the title attributes of <a> elements\n",
    "for h3_element in h3_elements:\n",
    "    a_element = h3_element.find('a')  # Find the <a> element within each <h3>\n",
    "    if a_element:\n",
    "        title_attribute = a_element.get('title')  # Extract the title attribute\n",
    "        title_attributes.append(title_attribute)  # Append the title attribute to the list\n",
    "\n",
    "print(\"Title Attributes List:\", title_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent.  Now we have a list of titles!  \n",
    "\n",
    "In order to write them to a file, we need to convert the items in the list to a string first.  The `write()` method expects strings as input.\n",
    "\n",
    "A string is a sequence of characters, which can be letters, numbers, symbols, or spaces enclosed within either single or double quotes.  Strings are immutable, meaning their contents cannot be changed after creation.  \n",
    "\n",
    "`str(title)` will convert each title in the list into a string.  `\\n` will add a line break after every title, so each one will be on a separate line in the text file.  \n",
    "\n",
    "Run the code below.  Check the contents of your file by clicking on it in the file explorer on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('title_list.txt', 'w') as outfile:\n",
    "    outfile.writelines((str(title)+'\\n' for title in title_attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done!  That was a complex set of problems we explored.  In the next lesson, we will look at getting all the data connected to each title, price, rating, stock status, etc., so we will have a dataset that can provide some real insight into the store's selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
